# -*- coding: utf-8 -*-
"""nti project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16KK73vj8oQ5SikLtqV6_Osfl3zSvVo6t
"""

# Downloading Dataset
import kagglehub
import os

# Analysing and Visualizing Data Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn import metrics, tree
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Spliting Libraries
from sklearn.model_selection import train_test_split

# Logistic Regression Libraries
from sklearn.linear_model import LogisticRegression

# Random Forest Libraries
from sklearn.ensemble import RandomForestClassifier

# Making Diffrent Models and downloading them
from google.colab import files
import joblib

"""#**Importing Datasets**"""

mragpavank_heart_diseaseuci_path = kagglehub.dataset_download('mragpavank/heart-diseaseuci')
print('Data source import complete.')
df = pd.read_csv(os.path.join(mragpavank_heart_diseaseuci_path, 'heart.csv'))

"""#**Printing Head**"""

df.head()

"""#**Printing info**"""

df.info()

"""#**Checking Nulls**"""

df.isnull().sum()

"""#**Print Describtion**"""

df.describe()

"""#**Print Unique Values**"""

print("the uniqe values of thal:\n")
df['thal'].unique()

print("the uniqe values of the cp :\n")
df['cp'].unique()

"""#**Analyzing Important Features**"""

countNoDisease = len(df[df.target == 0])
countHaveDisease = len(df[df.target == 1])
print("Percentage of Patients Haven't Heart Disease: {:.2f}%".format((countNoDisease / (len(df.target))*100)))
print("Percentage of Patients Have Heart Disease: {:.2f}%".format((countHaveDisease / (len(df.target))*100)))

print(df.groupby('thal')['target'].value_counts(normalize=True))
print(df.groupby('cp')['target'].value_counts(normalize=True))

"""#**EDA**"""

sns.countplot(x='target', data=df)
plt.title("Target Distribution")
plt.show()

plt.figure(figsize=(8,6))
sns.countplot(x='sex', hue='target', data=df, palette='Set2')
plt.title("Relation between Sex and Heart Disease")
plt.xlabel("Sex (0 = Female, 1 = Male)")
plt.ylabel("Count")
plt.legend(title="Target (0 = No Disease, 1 = Disease)")
plt.show()

plt.figure(figsize=(20,16))
sns.countplot(x='age', hue='target', data=df, palette='Set2')
plt.title("Relation between age and Heart Disease")
plt.xlabel("age")
plt.ylabel("Count")
plt.legend(title="Target (0 = No Disease, 1 = Disease)")
plt.show()

num_cols = ['age','trestbps','chol','thalach','oldpeak']
df[num_cols].hist(figsize=(10,8))
plt.show()

features = ['trestbps', 'chol', 'fbs',	'restecg', 'thalach',	'exang', 'oldpeak',	'slope', 'ca', 'thal']

plt.figure(figsize=(15, 20))

for i, feature in enumerate(features, 1):
    plt.subplot(6, 3, i)
    sns.boxplot(y=df[feature], color="red")
    plt.title(feature, fontsize=10)

plt.tight_layout()
plt.show()

plt.figure(figsize=(20,16))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""#**Cleaning Data**"""

print(df.duplicated().sum())
df = df.drop_duplicates()

# Replacing the outliers Function

def clip_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)

    return df

outlier_columns = ['trestbps', 'chol', 'fbs',	'restecg', 'thalach',	'exang', 'oldpeak',	'slope', 'ca', 'thal']

for col in outlier_columns:
    df = clip_outliers(df, col)

df.round().astype(int)

"""#**Visualize After Cleaning**"""

features = ['trestbps', 'chol', 'fbs',	'restecg', 'thalach',	'exang', 'oldpeak',	'slope', 'ca', 'thal']

plt.figure(figsize=(15, 20))

for i, feature in enumerate(features, 1):
    plt.subplot(6, 3, i)
    sns.boxplot(y=df[feature], color="red")
    plt.title(feature, fontsize=10)

plt.tight_layout()
plt.show()

"""#**Spliting Data**"""

X = df.drop(columns=['target'])
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""#**Logistic Regression**"""

logistic_model = LogisticRegression(max_iter=5000, random_state=42, class_weight="balanced")
logistic_model.fit(X_train, y_train)
y_pred = logistic_model.predict(X_test)

# testing the model
print("=== Logistic Regression ===")
print("Train Accuracy:", accuracy_score(y_train, logistic_model.predict(X_train)))
print("Test Accuracy :", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion matrix of Results from Logistic Regression
cm = metrics.confusion_matrix(y_test, logistic_model.predict(X_test))
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])
cm_display.plot()
plt.show()

# Checking the performance of the model
y_pred_svc_df = pd.DataFrame({'Expected':y_test, 'Predicted':y_pred })
y_pred_svc_df.head(10)

joblib.dump(logistic_model, "logistic_model.pkl")

"""#**Random Forest**"""

random_forest_model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight="balanced")
random_forest_model.fit(X_train, y_train)
y_pred = random_forest_model.predict(X_test)

# testing the model
print("=== Random Forest ===")
print("Train Accuracy:", accuracy_score(y_train, random_forest_model.predict(X_train)))
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion matrix of Results from Random Forest
cm = metrics.confusion_matrix(y_test, random_forest_model.predict(X_test))
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])
cm_display.plot()
plt.show()

# Checking the performance of the model
y_pred_df = pd.DataFrame({'Expected':y_test, 'Predicted':y_pred })
y_pred_df.head(10)

joblib.dump(random_forest_model, "random_forest_model.pkl")

"""#**Downloading Models**"""

files.download("logistic_model.pkl")
files.download("random_forest_model.pkl")